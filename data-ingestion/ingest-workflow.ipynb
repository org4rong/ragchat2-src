{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59bfe165",
   "metadata": {},
   "source": [
    "# Notebook to use RAGDocument and LlamaStackClient to store documents in PGVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaf2364-f318-4763-a5af-f0277f334d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/app-root/lib64/python3.11/site-packages (25.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install boto3 pandas\n",
    "!pip install docstring-parser==0.7.3 kfp-pipeline-spec==0.6.0 kfp-server-api==2.1.0 kubernetes==8.0.0 protobuf==4.21.1 requests-toolbelt==0.8.0\n",
    "!pip install llama-stack\n",
    "!pip install sentence-transformers\n",
    "!pip install llama-stack-client==0.1.9\n",
    "!pip install huggingface_hub==0.14.1\n",
    "!pip install numpy\n",
    "!pip install pdfplumber\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fce794-07aa-406f-ac77-343747fe6de5",
   "metadata": {},
   "source": [
    "### Fetch from minIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1dacf488-7fe9-4210-a1e9-e9c5f154c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.dsl import component, InputPath, OutputPath\n",
    "from kfp.v2 import compiler\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.10\",\n",
    "    packages_to_install=[\"boto3\", \"pandas\", \"llama-stack\", \"httpx\", \"numpy\", \"psycopg2\", \"llama-stack-client==0.1.9\"]\n",
    ")\n",
    "def fetch_from_minio(\n",
    "    bucket_name: str,\n",
    "    file_key: str,\n",
    "    minio_endpoint: str,\n",
    "    minio_access_key: str,\n",
    "    minio_secret_key: str,\n",
    "    output_file: OutputPath()\n",
    "):\n",
    "    import boto3\n",
    "    import os\n",
    "\n",
    "    s3 = boto3.client(\n",
    "        \"s3\",\n",
    "        endpoint_url=minio_endpoint,\n",
    "        aws_access_key_id=minio_access_key,\n",
    "        aws_secret_access_key=minio_secret_key\n",
    "    )\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    s3.download_file(bucket_name, file_key, output_file)\n",
    "    print(f\"File downloaded to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ec5cce",
   "metadata": {},
   "source": [
    "### Chunk and Store Embeddings in PGVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e794b5-e462-4bc4-b2a2-9173528b5f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import dsl\n",
    "from kfp.dsl import component, Input, InputPath, Output, OutputPath\n",
    "import os\n",
    "import json\n",
    "from llama_stack_client import LlamaStackClient\n",
    "from llama_stack_client.types import Document as LlamaStackDocument\n",
    "\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling_core.transforms.chunker.hybrid_chunker import HybridChunker\n",
    "from docling_core.types.doc.labels import DocItemLabel\n",
    "\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.10\",\n",
    "    packages_to_install=[\n",
    "        \"llama-stack-client==0.1.9\",\n",
    "        \"docling\",\n",
    "        \"docling-core\"\n",
    "    ]\n",
    ")\n",
    "def chunk_embed_and_store(\n",
    "    input_file: InputPath(),\n",
    "    llama_stack_url: str = \"http://localhost:8321\",\n",
    "    embedding_model: str = \"all-MiniLM-L6-v2\",\n",
    "    embedding_dimension: int = 384,\n",
    "    provider_id: str = \"pgvector\",\n",
    "    vector_db_id: str = \"my_document_db\"\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Process documents, convert them to chunks, and store in a vector database.\n",
    "    \n",
    "    Args:\n",
    "        input_file (InputPath): Path to the document or a JSON file containing document paths\n",
    "        llama_stack_url (str): URL for the Llama Stack API\n",
    "        embedding_model (str): Model to use for embeddings\n",
    "        embedding_dimension (int): Dimension size for embeddings\n",
    "        provider_id (str): Provider ID for vector database\n",
    "        vector_db_id (str): ID for the vector database\n",
    "        \n",
    "    Returns:\n",
    "        int: Number of documents processed\n",
    "    \"\"\"\n",
    "    # === Step 1: Configure Llama Stack client ===\n",
    "    client = LlamaStackClient(base_url=llama_stack_url)\n",
    "\n",
    "    # === Step 2: Process document path ===\n",
    "    # The document_path could be a single file or a JSON file with multiple document paths\n",
    "    documents = []\n",
    "    if os.path.isfile(input_file):\n",
    "        # Check if this is a JSON file with a list of document paths\n",
    "        if input_file.endswith('.json'):\n",
    "            try:\n",
    "                with open(input_file, 'r') as f:\n",
    "                    file_data = json.load(f)\n",
    "                    if isinstance(file_data, list):\n",
    "                        documents = file_data\n",
    "                    elif isinstance(file_data, dict) and 'input_file' in file_data:\n",
    "                        documents = file_data['input_file']\n",
    "                    elif isinstance(file_data, dict) and 'documents' in file_data:\n",
    "                        documents = file_data['documents']\n",
    "                    else:\n",
    "                        documents = [input_file]\n",
    "            except json.JSONDecodeError:\n",
    "                documents = [input_file]\n",
    "        else:\n",
    "            documents = [input_file]\n",
    "\n",
    "    # === Step 3: Convert, Chunk, and Prepare Documents ===\n",
    "    # converter format option for the pictures on pdf to be generated as base64\n",
    "    pipeline_options = PdfPipelineOptions()\n",
    "    pipeline_options.generate_picture_images = True\n",
    "    converter = DocumentConverter(\n",
    "                format_options={\n",
    "                    InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "                }\n",
    "    )\n",
    "    chunker = HybridChunker()\n",
    "    llama_documents: list[LlamaStackDocument] = []\n",
    "    i = 0\n",
    "\n",
    "    for file_path in documents:\n",
    "        print(f\"Processing {file_path}...\")\n",
    "        try:\n",
    "            docling_doc = converter.convert(source=file_path).document\n",
    "            chunks = chunker.chunk(docling_doc)\n",
    "            chunk_count = 0\n",
    "\n",
    "            for chunk in chunks:\n",
    "                if any(\n",
    "                    c.label in [DocItemLabel.TEXT, DocItemLabel.PARAGRAPH]\n",
    "                    for c in chunk.meta.doc_items\n",
    "                ):\n",
    "                    i += 1\n",
    "                    chunk_count += 1\n",
    "                    llama_documents.append(\n",
    "                        LlamaStackDocument(\n",
    "                            document_id=f\"doc-{i}\",\n",
    "                            content=chunk.text,\n",
    "                            mime_type=\"text/plain\",\n",
    "                            metadata={\"source\": file_path},\n",
    "                        )\n",
    "                    )\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_message = str(e)\n",
    "            print(f\"Error processing {file_path}: {error_message}\")\n",
    "\n",
    "    total_chunks = len(llama_documents)\n",
    "    print(f\"Total valid documents prepared: {total_chunks}\")\n",
    "\n",
    "    # === Step 4: Create Vector DB ===\n",
    "    try:\n",
    "        client.vector_dbs.register(\n",
    "            vector_db_id=vector_db_id,\n",
    "            embedding_model=embedding_model,\n",
    "            embedding_dimension=embedding_dimension,\n",
    "            provider_id=provider_id,\n",
    "        )\n",
    "        print(f\"Vector DB registered successfully: {vector_db_id}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = str(e)\n",
    "        print(f\"Failed to register vector DB '{vector_db_id}': {error_message}\")\n",
    "\n",
    "    # === Step 5: Insert into Vector DB ===\n",
    "    try:\n",
    "        client.tool_runtime.rag_tool.insert(\n",
    "            documents=llama_documents,\n",
    "            vector_db_id=vector_db_id,\n",
    "            chunk_size_in_tokens=512,\n",
    "        )\n",
    "        print(\"Documents successfully inserted into the vector DB.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = str(e)\n",
    "        print(f\"Error inserting documents into RAG tool: {error_message}\")\n",
    "\n",
    "    print(f\"Total chunks inserted into vectordb: {total_chunks}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcde705-c409-4a71-a008-2a07c0ae2623",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4096783f-a32d-4231-8d1f-b3e51f6afe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.dsl import pipeline\n",
    "from kfp.v2 import compiler\n",
    "\n",
    "@pipeline(name=\"pipeline-fetch-chunk-embed-store-vector-db\")\n",
    "def full_pipeline():\n",
    "    fetch_step = fetch_from_minio(\n",
    "        bucket_name=\"llama\",\n",
    "        file_key=\"abc.pdf\",\n",
    "        minio_endpoint=\"<mino-api-url>\",\n",
    "        minio_access_key=\"<minio_username>\",\n",
    "        minio_secret_key=\"<minio_password>\"\n",
    "    )\n",
    "\n",
    "    chunk_and_embed_step = chunk_embed_and_store(\n",
    "        input_file=fetch_step.outputs[\"output_file\"],\n",
    "        llama_stack_url=\"<your-llama-stack-url>\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5a68fd-c0ac-49e2-b5b8-7322fe3e07f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=full_pipeline,\n",
    "    package_path=\"fetch_chunk_embed_pipeline.yaml\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
